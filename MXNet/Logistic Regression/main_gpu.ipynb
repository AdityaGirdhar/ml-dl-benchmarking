{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the libraries and packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages and libraries\n",
    "from mxnet import nd, gluon, autograd\n",
    "from mxnet.gluon import nn\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mxnet import profiler\n",
    "import time\n",
    "import re\n",
    "data_ctx = mx.gpu()\n",
    "model_ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the profiler for measuring the execution time and memory usage\n",
    "profiler.set_config(profile_all=False,profile_symbolic = False, profile_imperative = False,profile_memory = True, profile_api = True,aggregate_stats=True,continuous_dump=False, filename='log_reg_gpu_profile.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and pre-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('magic_gamma_telescope.csv', header=None)\n",
    "\n",
    "# extract the features and labels\n",
    "X = df.iloc[:, :-1].values.astype(np.float32)\n",
    "y_labels = df.iloc[:, -1].values\n",
    "\n",
    "# encode the string class labels as integers\n",
    "y_labels[y_labels == 'g'] = 0\n",
    "y_labels[y_labels == 'h'] = 1\n",
    "y = y_labels.astype(np.int32)\n",
    "\n",
    "# convert the features and labels to mxnet ndarrays\n",
    "X = nd.array(X, ctx=data_ctx)\n",
    "y = nd.array(y, ctx=data_ctx)\n",
    "y = y.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19020, 10)\n",
      "(19020, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + nd.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "learning_rate = 0.1\n",
    "num_of_epochs = 10\n",
    "batch_size = 10\n",
    "weights = nd.random_normal(shape=(X.shape[1], 1), ctx=model_ctx)\n",
    "bias = 0\n",
    "num_samples, num_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = gluon.data.ArrayDataset(X, y)\n",
    "data_loader = gluon.data.DataLoader(data_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the neural network\n",
    "net = nn.Sequential()\n",
    "# Adding the output layer with only one output, with the sigmoid activation function\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(units=1, activation='sigmoid'))\n",
    "# collect_params() will initialize the weights and biases for the neural network\n",
    "net.collect_params().initialize(mx.init.Zero(), ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the loss function and the optimizer\n",
    "loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(params = net.collect_params(), optimizer='sgd', optimizer_params={'learning_rate': learning_rate})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function():\n",
    "    cumulative_loss = 0\n",
    "    # for each epoch, iterating over the dataset in batches\n",
    "    for i, (data, label) in enumerate(data_loader):\n",
    "        # for the forward pass\n",
    "        with autograd.record():\n",
    "            output = net(data)      # output is the predicted value from the neural network\n",
    "            L = loss(output, label) # L will store the loss between the predicted value and the actual value\n",
    "        L.backward()                # for the backward pass\n",
    "        trainer.step(batch_size)    # updating the weights and biases\n",
    "        cumulative_loss += nd.sum(L).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running one epoch before profiling\n",
    "training_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.nd.waitall() \n",
    "\n",
    "# starting the profiler\n",
    "start = time.time()\n",
    "profiler.set_state('run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_of_epochs):\n",
    "    training_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waiting for all operations to end, then stopping the profiler\n",
    "mx.nd.waitall()\n",
    "end = time.time()\n",
    "profiler.set_state('stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = profiler.dumps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results\n",
    "result = result.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the result into a list of lists\n",
    "for i in range(len(result)):\n",
    "    result[i] = result[i].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the maximum gpu and cpu memory usage and the total execution time\n",
    "max_gpu_use = 0\n",
    "max_cpu_use = 0\n",
    "total_execution_time = 0\n",
    "# traversing over the lists and trying to find the maximum gpu and cpu memory usage and the total execution time\n",
    "for i in result:\n",
    "    if (len(i)>=1 and i[0]=='Memory:'):\n",
    "        if (i[1]=='gpu/0'):\n",
    "            max_gpu_use = float(i[-2])\n",
    "        elif (i[1]=='cpu/0'):\n",
    "            max_cpu_use = float(i[-2])\n",
    "        else: continue\n",
    "    # if the length of the list 6 and the second to sixth elements are numbers, then it is a time entry\n",
    "    else:\n",
    "        if (len(i)>=6):\n",
    "            # if it is a valid time entry, then add it to the total execution time\n",
    "            if (re.match(r'^-?\\d+(?:\\.\\d+)$', i[-4]) is not None):\n",
    "                total_execution_time += float(i[-4])\n",
    "\n",
    "if (total_execution_time==0):\n",
    "    total_execution_time = (end - start)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum GPU memory usage: 1.12 KB\n",
      "Maximum CPU memory usage: 0 KB\n",
      "Total execution time: 29794.202499999996 milli seconds (ms)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum GPU memory usage: {max_gpu_use} KB\")\n",
    "print(f\"Maximum CPU memory usage: {max_cpu_use} KB\")\n",
    "print(f\"Total execution time: {total_execution_time} milli seconds (ms)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
