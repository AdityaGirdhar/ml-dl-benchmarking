{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages and libraries\n",
    "from mxnet import nd, gluon, autograd\n",
    "from mxnet.gluon import nn\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from mxnet import profiler\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ctx = mx.gpu()\n",
    "model_ctx = mx.gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(\n",
    "    # Here, we use a larger 11 x 11 window to capture objects. At the same time,\n",
    "   # we use a stride of 4 to greatly reduce the height and width of the output.\n",
    "    nn.Conv2D(96,kernel_size=11,strides=4,activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=3,strides=2),\n",
    "    # Make the convolution window smaller, set padding to 2 for consistent\n",
    "    # height and width across the input and output, and increase the\n",
    "    # number of output channels\n",
    "    nn.Conv2D(256,kernel_size=5,padding=2,activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=3,strides=2),\n",
    "    # Use three successive convolutional layers and a smaller convolution\n",
    "    # window. Except for the final convolutional layer, the number of\n",
    "    # output channels is further increased. Pooling layers are not used to\n",
    "    # reduce the height and width of input after the first two\n",
    "    # convolutional layers\n",
    "   nn.Conv2D(384, kernel_size=3,padding=1,activation='relu'),\n",
    "   nn.Conv2D(384, kernel_size=3,padding=1,activation='relu'),\n",
    "   nn.Conv2D(256, kernel_size=3,padding=1,activation='relu'),\n",
    "   nn.MaxPool2D(pool_size=3, strides=2),\n",
    "   nn.Dense(4096,activation='relu'),\n",
    "   nn.Dropout(.5),\n",
    "   nn.Dense(4096,activation='relu'),\n",
    "   nn.Dropout(0.5),\n",
    "   nn.Dense(10)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "HybridBlock requires the first argument to forward be either Symbol or NDArray, but got <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-48bbfa290151>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'output shape:\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Public\\ipenv\\envs\\env1\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Public\\ipenv\\envs\\env1\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;34m\"HybridBlock requires the first argument to forward be either \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m             \u001b[1;34m\"Symbol or NDArray, but got %s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: HybridBlock requires the first argument to forward be either Symbol or NDArray, but got <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "X = np.random.uniform(size=(1,1,224,224))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "  X=layer(X)\n",
    "  print(layer.name,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licensed to the Apache Software Foundation (ASF) under one\n",
    "# or more contributor license agreements.  See the NOTICE file\n",
    "# distributed with this work for additional information\n",
    "# regarding copyright ownership.  The ASF licenses this file\n",
    "# to you under the Apache License, Version 2.0 (the\n",
    "# \"License\"); you may not use this file except in compliance\n",
    "# with the License.  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing,\n",
    "# software distributed under the License is distributed on an\n",
    "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "# KIND, either express or implied.  See the License for the\n",
    "# specific language governing permissions and limitations\n",
    "# under the License.\n",
    "\n",
    "# coding: utf-8\n",
    "# pylint: disable= arguments-differ\n",
    "\"\"\"Alexnet, implemented in Gluon.\"\"\"\n",
    "__all__ = ['AlexNet', 'alexnet']\n",
    "\n",
    "import os\n",
    "\n",
    "# from ....context import cpu\n",
    "from mxnet.context import cpu\n",
    "from mxnet.gluon.block import HybridBlock\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "# Net\n",
    "class AlexNet(HybridBlock):\n",
    "    r\"\"\"AlexNet model from the `\"One weird trick...\" `_ paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classes : int, default 1000\n",
    "        Number of classes for the output layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, classes=1000, **kwargs):\n",
    "        super(AlexNet, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.features = nn.HybridSequential(prefix='')\n",
    "            with self.features.name_scope():\n",
    "                self.features.add(nn.Conv2D(64, kernel_size=11, strides=4,\n",
    "                                            padding=2, activation='relu'))\n",
    "                self.features.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "                self.features.add(nn.Conv2D(192, kernel_size=5, padding=2,\n",
    "                                            activation='relu'))\n",
    "                self.features.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "                self.features.add(nn.Conv2D(384, kernel_size=3, padding=1,\n",
    "                                            activation='relu'))\n",
    "                self.features.add(nn.Conv2D(256, kernel_size=3, padding=1,\n",
    "                                            activation='relu'))\n",
    "                self.features.add(nn.Conv2D(256, kernel_size=3, padding=1,\n",
    "                                            activation='relu'))\n",
    "                self.features.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "                self.features.add(nn.Flatten())\n",
    "                self.features.add(nn.Dense(4096, activation='relu'))\n",
    "                self.features.add(nn.Dropout(0.5))\n",
    "                self.features.add(nn.Dense(4096, activation='relu'))\n",
    "                self.features.add(nn.Dropout(0.5))\n",
    "\n",
    "            self.output = nn.Dense(classes)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Constructor\n",
    "def alexnet(pretrained=False, ctx=cpu(),\n",
    "            root=os.path.join('~', '.mxnet', 'models'), **kwargs):\n",
    "    r\"\"\"AlexNet model from the `\"One weird trick...\" `_ paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    ctx : Context, default CPU\n",
    "        The context in which to load the pretrained weights.\n",
    "    root : str, default '~/.mxnet/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    net = AlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        from ..model_store import get_model_file\n",
    "        net.load_params(get_model_file('alexnet', root=root), ctx=ctx)\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import np,npx,init\n",
    "from mxnet.gluon import nn\n",
    "import mxnet as d2l\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add(\n",
    "    # Here, we use a larger 11 x 11 window to capture objects. At the same time,\n",
    "   # we use a stride of 4 to greatly reduce the height and width of the output.\n",
    "    nn.Conv2D(96,kernel_size=11,strides=4,activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=3,strides=2),\n",
    "    # Make the convolution window smaller, set padding to 2 for consistent\n",
    "    # height and width across the input and output, and increase the\n",
    "    # number of output channels\n",
    "    nn.Conv2D(256,kernel_size=5,padding=2,activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=3,strides=2),\n",
    "    # Use three successive convolutional layers and a smaller convolution\n",
    "    # window. Except for the final convolutional layer, the number of\n",
    "    # output channels is further increased. Pooling layers are not used to\n",
    "    # reduce the height and width of input after the first two\n",
    "    # convolutional layers\n",
    "   nn.Conv2D(384, kernel_size=3,padding=1,activation='relu'),\n",
    "   nn.Conv2D(384, kernel_size=3,padding=1,activation='relu'),\n",
    "   nn.Conv2D(256, kernel_size=3,padding=1,activation='relu'),\n",
    "   nn.MaxPool2D(pool_size=3, strides=2),\n",
    "   nn.Dense(4096,activation='relu'),\n",
    "   nn.Dropout(.5),\n",
    "   nn.Dense(4096,activation='relu'),\n",
    "   nn.Dropout(0.5),\n",
    "   nn.Dense(10)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0 output shape:\t (1, 96, 54, 54)\n",
      "pool0 output shape:\t (1, 96, 26, 26)\n",
      "conv1 output shape:\t (1, 256, 26, 26)\n",
      "pool1 output shape:\t (1, 256, 12, 12)\n",
      "conv2 output shape:\t (1, 384, 12, 12)\n",
      "conv3 output shape:\t (1, 384, 12, 12)\n",
      "conv4 output shape:\t (1, 256, 12, 12)\n",
      "pool2 output shape:\t (1, 256, 5, 5)\n",
      "dense0 output shape:\t (1, 4096)\n",
      "dropout0 output shape:\t (1, 4096)\n",
      "dense1 output shape:\t (1, 4096)\n",
      "dropout1 output shape:\t (1, 4096)\n",
      "dense2 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.uniform(size=(1,1,224,224))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "  X=layer(X)\n",
    "  print(layer.name,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_data = d2l.gluon.data.vision.FashionMNIST(train = True, transform = None)\n",
    "train_iter = d2l.gluon.data.DataLoader(train_data, batch_size, shuffle = True)\n",
    "test_data = d2l.gluon.data.vision.FashionMNIST(train = False, transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mxnet' has no attribute 'train_ch6'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Prakhar Gupta\\Documents\\GitHub\\ml-dl-benchmarking\\MXNet\\AlexNet\\main_gpu.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Prakhar%20Gupta/Documents/GitHub/ml-dl-benchmarking/MXNet/AlexNet/main_gpu.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lr, num_epochs \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m,\u001b[39m10\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Prakhar%20Gupta/Documents/GitHub/ml-dl-benchmarking/MXNet/AlexNet/main_gpu.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m d2l\u001b[39m.\u001b[39;49mtrain_ch6(net,train_iter,test_iter,num_epochs,lr,d2l\u001b[39m.\u001b[39mtry_gpu())\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mxnet' has no attribute 'train_ch6'"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01,10\n",
    "d2l.train_ch6(net,train_iter,test_iter,num_epochs,lr,d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for prediction\n",
    "for X,y in test_iter:\n",
    "  X=X\n",
    "  y=y\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels=['t-shirt','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']\n",
    "    return text_labels[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,y):\n",
    "  trl=[]\n",
    "  prel=[]\n",
    "  count = 0\n",
    "  X=X.as_in_ctx(d2l.try_gpu())\n",
    "  z=net(X).argmax(axis=1)\n",
    "  n=len(z)\n",
    "  for i,j in zip(z,y):\n",
    "    pre=get_fashion_mnist_labels(int(i))\n",
    "    tru = get_fashion_mnist_labels(int(j))\n",
    "    if pre==tru:\n",
    "      count+=1\n",
    "    trl.append(tru)\n",
    "    prel.append(pre)\n",
    "  label = {'true_label':trl,'predicted_label':prel}\n",
    "  df = pd.DataFrame(label)\n",
    "  print(df)\n",
    "  print('The accuracy:',(count/n)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(X[:10],y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
